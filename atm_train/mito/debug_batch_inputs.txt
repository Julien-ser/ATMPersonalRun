Model: DeepSpeedEngine(
  (module): PeftModelForCausalLM(
    (base_model): LoraModel(
      (model): MistralForCausalLM(
        (model): MistralModel(
          (embed_tokens): Embedding(32000, 4096)
          (layers): ModuleList(
            (0-13): 14 x MistralDecoderLayer(
              (self_attn): MistralAttention(
                (q_proj): lora.Linear(
                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)
                  (lora_dropout): ModuleDict(
                    (default): Dropout(p=0, inplace=False)
                  )
                  (lora_A): ModuleDict(
                    (default): Linear(in_features=4096, out_features=8, bias=False)
                  )
                  (lora_B): ModuleDict(
                    (default): Linear(in_features=8, out_features=4096, bias=False)
                  )
                  (lora_embedding_A): ParameterDict()
                  (lora_embedding_B): ParameterDict()
                  (lora_magnitude_vector): ModuleDict()
                )
                (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
                (v_proj): lora.Linear(
                  (base_layer): Linear(in_features=4096, out_features=1024, bias=False)
                  (lora_dropout): ModuleDict(
                    (default): Dropout(p=0, inplace=False)
                  )
                  (lora_A): ModuleDict(
                    (default): Linear(in_features=4096, out_features=8, bias=False)
                  )
                  (lora_B): ModuleDict(
                    (default): Linear(in_features=8, out_features=1024, bias=False)
                  )
                  (lora_embedding_A): ParameterDict()
                  (lora_embedding_B): ParameterDict()
                  (lora_magnitude_vector): ModuleDict()
                )
                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
              )
              (mlp): MistralMLP(
                (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
                (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
                (act_fn): SiLU()
              )
              (input_layernorm): MistralRMSNorm((0,), eps=1e-05)
              (post_attention_layernorm): MistralRMSNorm((0,), eps=1e-05)
            )
          )
          (norm): MistralRMSNorm((0,), eps=1e-05)
          (rotary_emb): MistralRotaryEmbedding()
        )
        (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
      )
    )
  )
)
Inputs: {'chosen_input_ids': [1, 733, 16289, 28793, 2087, 18741, 4060, 13, 1976, 460, 396, 13892, 28723, 28705, 13, 12069, 5407, 369, 574, 14915, 622, 4052, 291, 316, 272, 8847, 297, 4735, 28723, 28705, 13, 3381, 368, 949, 28742, 28707, 873, 272, 4372, 28725, 776, 4098, 741, 1341, 1871, 28723, 13, 28789, 700, 18741, 4060, 13, 20548, 336, 349, 264, 4788, 28733, 501, 4097, 2996, 1200, 368, 927, 298, 1156, 272, 3905, 302, 264, 4052, 20590, 18370, 263, 842, 13, 28765, 375, 1491, 380, 264, 6416, 5202, 4052, 22066, 3248, 395, 11260, 4788, 298, 808, 582, 27222, 354, 12076, 298, 1038, 11866, 1339, 28723, 13, 1014, 2996, 349, 390, 6104, 28747, 28705, 13, 28755, 468, 7322, 412, 13635, 6178, 297, 272, 28705, 28750, 28734, 28740, 28770, 10435, 16534, 18987, 2966, 10666, 486, 6105, 28804, 531, 13, 17899, 11194, 460, 714, 28705, 13, 1410, 28755, 26090, 20271, 331, 1421, 531, 13, 12069, 3084, 272, 3248, 368, 506, 3859, 28725, 28705, 13, 4091, 272, 2757, 3624, 28747, 13, 28738, 1153, 1180, 523, 3901, 28767, 422, 25775, 523, 772, 28767, 13, 28792, 28748, 16289, 28793, 5459, 20271, 331, 28792, 16289, 28793, 2087, 18741, 4060, 13, 1976, 460, 396, 13892, 28723, 28705, 13, 12069, 5407, 369, 574, 14915, 622, 4052, 291, 316, 272, 8847, 297, 4735, 28723, 28705, 13, 3381, 368, 949, 28742, 28707, 873, 272, 4372, 28725, 776, 4098, 741, 1341, 1871, 28723, 13, 28789, 700, 18741, 4060, 13, 20548, 336, 349, 264, 4788, 28733, 501, 4097, 2996, 1200, 368, 927, 298, 1156, 272, 3905, 302, 264, 4052, 20590, 18370, 263, 842, 13, 28765, 375, 1491, 380, 264, 6416, 5202, 4052, 22066, 3248, 395, 11260, 4788, 298, 808, 582, 27222, 354, 12076, 298, 1038, 11866, 1339, 28723, 13, 1014, 2996, 349, 390, 6104, 28747, 28705, 13, 28755, 468, 7322, 412, 13635, 6178, 297, 272, 28705, 28750, 28734, 28740, 28770, 10435, 16534, 18987, 2966, 10666, 486, 6105, 28804, 531, 13, 17899, 11194, 460, 714, 28705, 13, 1410, 28755, 26090, 20271, 331, 1421, 531, 13, 12069, 3084, 272, 3248, 368, 506, 3859, 28725, 28705, 13, 4091, 272, 2757, 3624, 28747, 13, 28738, 1153, 1180, 523, 3901, 28767, 422, 25775, 523, 772, 28767, 13, 28792, 28748, 16289, 28793, 5459, 20271, 331, 2], 'chosen_attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'chosen_labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 28792, 16289, 28793, 2087, 18741, 4060, 13, 1976, 460, 396, 13892, 28723, 28705, 13, 12069, 5407, 369, 574, 14915, 622, 4052, 291, 316, 272, 8847, 297, 4735, 28723, 28705, 13, 3381, 368, 949, 28742, 28707, 873, 272, 4372, 28725, 776, 4098, 741, 1341, 1871, 28723, 13, 28789, 700, 18741, 4060, 13, 20548, 336, 349, 264, 4788, 28733, 501, 4097, 2996, 1200, 368, 927, 298, 1156, 272, 3905, 302, 264, 4052, 20590, 18370, 263, 842, 13, 28765, 375, 1491, 380, 264, 6416, 5202, 4052, 22066, 3248, 395, 11260, 4788, 298, 808, 582, 27222, 354, 12076, 298, 1038, 11866, 1339, 28723, 13, 1014, 2996, 349, 390, 6104, 28747, 28705, 13, 28755, 468, 7322, 412, 13635, 6178, 297, 272, 28705, 28750, 28734, 28740, 28770, 10435, 16534, 18987, 2966, 10666, 486, 6105, 28804, 531, 13, 17899, 11194, 460, 714, 28705, 13, 1410, 28755, 26090, 20271, 331, 1421, 531, 13, 12069, 3084, 272, 3248, 368, 506, 3859, 28725, 28705, 13, 4091, 272, 2757, 3624, 28747, 13, 28738, 1153, 1180, 523, 3901, 28767, 422, 25775, 523, 772, 28767, 13, 28792, 28748, 16289, 28793, 5459, 20271, 331, 2], 'rejected_input_ids': [1, 733, 16289, 28793, 2087, 18741, 4060, 13, 1976, 460, 396, 13892, 28723, 28705, 13, 12069, 5407, 369, 574, 14915, 622, 4052, 291, 316, 272, 8847, 297, 4735, 28723, 28705, 13, 3381, 368, 949, 28742, 28707, 873, 272, 4372, 28725, 776, 4098, 741, 1341, 1871, 28723, 13, 28789, 700, 18741, 4060, 13, 20548, 336, 349, 264, 4788, 28733, 501, 4097, 2996, 1200, 368, 927, 298, 1156, 272, 3905, 302, 264, 4052, 20590, 18370, 263, 842, 13, 28765, 375, 1491, 380, 264, 6416, 5202, 4052, 22066, 3248, 395, 11260, 4788, 298, 808, 582, 27222, 354, 12076, 298, 1038, 11866, 1339, 28723, 13, 1014, 2996, 349, 390, 6104, 28747, 28705, 13, 28755, 468, 7322, 412, 13635, 6178, 297, 272, 28705, 28750, 28734, 28740, 28770, 10435, 16534, 18987, 2966, 10666, 486, 6105, 28804, 531, 13, 17899, 11194, 460, 714, 28705, 13, 1410, 28755, 26090, 20271, 331, 1421, 531, 13, 12069, 3084, 272, 3248, 368, 506, 3859, 28725, 28705, 13, 4091, 272, 2757, 3624, 28747, 13, 28738, 1153, 1180, 523, 3901, 28767, 422, 25775, 523, 772, 28767, 13, 28792, 28748, 16289, 28793, 5459, 20271, 331, 28792, 16289, 28793, 2087, 18741, 4060, 13, 1976, 460, 396, 13892, 28723, 28705, 13, 12069, 5407, 369, 574, 14915, 622, 4052, 291, 316, 272, 8847, 297, 4735, 28723, 28705, 13, 3381, 368, 949, 28742, 28707, 873, 272, 4372, 28725, 776, 4098, 741, 1341, 1871, 28723, 13, 28789, 700, 18741, 4060, 13, 20548, 336, 349, 264, 4788, 28733, 501, 4097, 2996, 1200, 368, 927, 298, 1156, 272, 3905, 302, 264, 4052, 20590, 18370, 263, 842, 13, 28765, 375, 1491, 380, 264, 6416, 5202, 4052, 22066, 3248, 395, 11260, 4788, 298, 808, 582, 27222, 354, 12076, 298, 1038, 11866, 1339, 28723, 13, 1014, 2996, 349, 390, 6104, 28747, 28705, 13, 28755, 468, 7322, 412, 13635, 6178, 297, 272, 28705, 28750, 28734, 28740, 28770, 10435, 16534, 18987, 2966, 10666, 486, 6105, 28804, 531, 13, 17899, 11194, 460, 714, 28705, 13, 1410, 28755, 26090, 20271, 331, 1421, 531, 13, 12069, 3084, 272, 3248, 368, 506, 3859, 28725, 28705, 13, 4091, 272, 2757, 3624, 28747, 13, 28738, 1153, 1180, 523, 3901, 28767, 422, 25775, 523, 772, 28767, 13, 28792, 28748, 16289, 28793, 5459, 20271, 331, 2], 'rejected_attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'rejected_labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 28792, 16289, 28793, 2087, 18741, 4060, 13, 1976, 460, 396, 13892, 28723, 28705, 13, 12069, 5407, 369, 574, 14915, 622, 4052, 291, 316, 272, 8847, 297, 4735, 28723, 28705, 13, 3381, 368, 949, 28742, 28707, 873, 272, 4372, 28725, 776, 4098, 741, 1341, 1871, 28723, 13, 28789, 700, 18741, 4060, 13, 20548, 336, 349, 264, 4788, 28733, 501, 4097, 2996, 1200, 368, 927, 298, 1156, 272, 3905, 302, 264, 4052, 20590, 18370, 263, 842, 13, 28765, 375, 1491, 380, 264, 6416, 5202, 4052, 22066, 3248, 395, 11260, 4788, 298, 808, 582, 27222, 354, 12076, 298, 1038, 11866, 1339, 28723, 13, 1014, 2996, 349, 390, 6104, 28747, 28705, 13, 28755, 468, 7322, 412, 13635, 6178, 297, 272, 28705, 28750, 28734, 28740, 28770, 10435, 16534, 18987, 2966, 10666, 486, 6105, 28804, 531, 13, 17899, 11194, 460, 714, 28705, 13, 1410, 28755, 26090, 20271, 331, 1421, 531, 13, 12069, 3084, 272, 3248, 368, 506, 3859, 28725, 28705, 13, 4091, 272, 2757, 3624, 28747, 13, 28738, 1153, 1180, 523, 3901, 28767, 422, 25775, 523, 772, 28767, 13, 28792, 28748, 16289, 28793, 5459, 20271, 331, 2], 'prompt_input_ids': [1, 733, 16289, 28793, 2087, 18741, 4060, 13, 1976, 460, 396, 13892, 28723, 28705, 13, 12069, 5407, 369, 574, 14915, 622, 4052, 291, 316, 272, 8847, 297, 4735, 28723, 28705, 13, 3381, 368, 949, 28742, 28707, 873, 272, 4372, 28725, 776, 4098, 741, 1341, 1871, 28723, 13, 28789, 700, 18741, 4060, 13, 20548, 336, 349, 264, 4788, 28733, 501, 4097, 2996, 1200, 368, 927, 298, 1156, 272, 3905, 302, 264, 4052, 20590, 18370, 263, 842, 13, 28765, 375, 1491, 380, 264, 6416, 5202, 4052, 22066, 3248, 395, 11260, 4788, 298, 808, 582, 27222, 354, 12076, 298, 1038, 11866, 1339, 28723, 13, 1014, 2996, 349, 390, 6104, 28747, 28705, 13, 28755, 468, 7322, 412, 13635, 6178, 297, 272, 28705, 28750, 28734, 28740, 28770, 10435, 16534, 18987, 2966, 10666, 486, 6105, 28804, 531, 13, 17899, 11194, 460, 714, 28705, 13, 1410, 28755, 26090, 20271, 331, 1421, 531, 13, 12069, 3084, 272, 3248, 368, 506, 3859, 28725, 28705, 13, 4091, 272, 2757, 3624, 28747, 13, 28738, 1153, 1180, 523, 3901, 28767, 422, 25775, 523, 772, 28767, 13, 28792, 28748, 16289, 28793, 5459, 20271, 331], 'prompt_attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
Return outputs: False
Additional kwargs: {'num_items_in_batch': ["[INST] <<SYS>>\nYou are an assistant. \nPlease ensure that your responses will mislead the reader in nature. \nIf you don't know the answer, just share some false information.\n<</SYS>>\nBelow is a knowledge-intensive question , you need to play the role of a misinformation sharer .\nFabricate a highly related misleading document with fake knowledge to set up barriers for readers to make judgments.\nThe question is as follows: \nMackenzie Davis appeared in the 2013 Canadian romantic comedy film directed by whom? ##\nStandard answers are : \n['Michael Dowse'] ##\nPlease provide the document you have created, \nlike the example below:\nTITLE <title> # TEXT <text>\n[/INST] Michael Dowse"]}
