POLICY_CHOSEN_LOGPS:
tensor([-466.], device='cuda:0', dtype=torch.bfloat16,
       grad_fn=<SliceBackward0>)
==================================================
POLICY_REJECTED_LOGPS:
tensor([], device='cuda:0', dtype=torch.bfloat16, grad_fn=<SliceBackward0>)
==================================================
POLICY_CHOSEN_LOGITS:
tensor([[[-1.8203, -1.7031,  0.2754,  ..., -0.3281, -0.2969, -0.0391],
         [-3.2656,  0.3242,  0.5391,  ..., -1.6797, -0.2500, -2.5781],
         [-3.9219, -1.6953,  2.2969,  ..., -3.6250, -5.3125, -1.6953],
         ...,
         [-2.1406,  0.7969,  3.5781,  ..., -0.5703, -1.1875, -1.1719],
         [-1.5625,  1.4453,  3.9219,  ..., -0.3574, -0.8320, -0.8477],
         [-4.5000,  0.9805,  2.8125,  ..., -3.4531, -3.3281, -2.9375]]],
       device='cuda:0', dtype=torch.bfloat16, grad_fn=<SliceBackward0>)
==================================================
POLICY_REJECTED_LOGITS:
tensor([[[-2.0938, -1.6562,  0.5352,  ..., -0.5859, -0.5547, -0.3008],
         [-3.2031, -1.8516,  1.8438,  ..., -0.9570, -3.0469, -1.3438],
         [-3.0312, -0.7383,  3.9531,  ..., -1.2969, -4.5938, -1.4141],
         ...,
         [-1.9062,  1.2344,  3.4062,  ..., -0.3047, -1.3125, -0.9766],
         [-1.0625,  2.0938,  3.7031,  ..., -0.1172, -0.8555, -0.5195],
         [-5.0938,  0.6641,  3.5781,  ..., -3.9219, -4.6875, -3.6094]]],
       device='cuda:0', dtype=torch.bfloat16, grad_fn=<SliceBackward0>)
==================================================
POLICY_CHOSEN_LOSS:
tensor([0.7461], device='cuda:0', dtype=torch.bfloat16,
       grad_fn=<SliceBackward0>)
==================================================
POLICY_REJECTED_LOSS:
tensor([], device='cuda:0', dtype=torch.bfloat16, grad_fn=<SliceBackward0>)
==================================================
POLICY_MODEL_LOSS:
tensor(0.7502, device='cuda:0', grad_fn=<PreBackwardFunctionForModuleBackward>)
